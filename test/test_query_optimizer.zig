const std = @import("std");
const testing = std.testing;
const contextdb = @import("contextdb");
const query_optimizer = contextdb.query_optimizer;

// Comprehensive Query Optimizer Tests
// Following TigerBeetle-style programming: deterministic, extensive, zero external dependencies

test "QueryStats basic operations" {
    var stats1 = query_optimizer.QueryStats.init();
    stats1.execution_time_ns = 1000;
    stats1.nodes_examined = 10;
    stats1.cache_hits = 5;
    stats1.cache_misses = 2;
    
    var stats2 = query_optimizer.QueryStats.init();
    stats2.execution_time_ns = 2000;
    stats2.nodes_examined = 20;
    stats2.cache_hits = 3;
    stats2.cache_misses = 1;
    
    const combined = stats1.combine(stats2);
    try testing.expect(combined.execution_time_ns == 3000);
    try testing.expect(combined.nodes_examined == 30);
    try testing.expect(combined.cache_hits == 8);
    try testing.expect(combined.cache_misses == 3);
    
    // Test cache hit ratio
    try testing.expect(stats1.getCacheHitRatio() > 0.7 and stats1.getCacheHitRatio() < 0.8);
    try testing.expect(combined.getCacheHitRatio() > 0.7 and combined.getCacheHitRatio() < 0.8);
    
    // Test efficiency score
    const efficiency = stats1.getEfficiencyScore();
    try testing.expect(efficiency > 0.0);
}

test "QueryStats edge cases" {
    // Test empty stats
    const empty_stats = query_optimizer.QueryStats.init();
    try testing.expect(empty_stats.getCacheHitRatio() == 0.0);
    try testing.expect(empty_stats.getEfficiencyScore() == 0.0);
    
    // Test all cache hits
    var all_hits = query_optimizer.QueryStats.init();
    all_hits.cache_hits = 10;
    all_hits.cache_misses = 0;
    try testing.expect(all_hits.getCacheHitRatio() == 1.0);
    
    // Test all cache misses
    var all_misses = query_optimizer.QueryStats.init();
    all_misses.cache_hits = 0;
    all_misses.cache_misses = 10;
    try testing.expect(all_misses.getCacheHitRatio() == 0.0);
}

test "QueryPlan basic functionality" {
    const allocator = testing.allocator;
    
    var plan = query_optimizer.QueryPlan.init(allocator, .index_lookup);
    defer plan.deinit();
    
    try testing.expect(plan.strategy == .index_lookup);
    try testing.expect(plan.estimated_cost == 1.0);
    try testing.expect(plan.expected_selectivity == 1.0);
    try testing.expect(plan.use_cache == true);
    try testing.expect(plan.use_parallel == false);
    
    // Test adding index hints
    try plan.addIndexHint("primary_index");
    try plan.addIndexHint("secondary_index");
    try testing.expect(plan.index_hints.items.len == 2);
    
    // Test priority calculation
    plan.estimated_cost = 2.0;
    plan.expected_selectivity = 0.5;
    const priority = plan.calculatePriority();
    try testing.expect(priority > 0.0);
}

test "QueryPattern initialization and updates" {
    var pattern = query_optimizer.QueryPattern.init(.point_lookup);
    try testing.expect(pattern.pattern_type == .point_lookup);
    try testing.expect(pattern.frequency == 0);
    try testing.expect(pattern.avg_execution_time == 0);
    try testing.expect(pattern.optimal_strategy == .index_lookup);
    
    // Test strategy mapping for different pattern types
    const similarity_pattern = query_optimizer.QueryPattern.init(.similarity_search);
    try testing.expect(similarity_pattern.optimal_strategy == .vector_similarity);
    
    const graph_pattern = query_optimizer.QueryPattern.init(.graph_traversal);
    try testing.expect(graph_pattern.optimal_strategy == .graph_traversal);
    
    // Test updating statistics
    pattern.updateStats(1000);
    try testing.expect(pattern.frequency == 1);
    try testing.expect(pattern.avg_execution_time == 1000);
    
    pattern.updateStats(2000);
    try testing.expect(pattern.frequency == 2);
    try testing.expect(pattern.avg_execution_time == 1500); // Average of 1000 and 2000
}

test "CostModel estimations" {
    const cost_model = query_optimizer.CostModel{};
    
    // Test linear scan cost
    const scan_cost = cost_model.estimateLinearScanCost(1000, 0.1);
    try testing.expect(scan_cost > 0.0);
    
    // Test index lookup cost
    const index_cost = cost_model.estimateIndexLookupCost(1000, 0.1);
    try testing.expect(index_cost > 0.0);
    
    // Test vector similarity cost
    const vector_cost = cost_model.estimateVectorSimilarityCost(100, 128);
    try testing.expect(vector_cost > 0.0);
    
    // Test graph traversal cost
    const graph_cost = cost_model.estimateGraphTraversalCost(4.0, 3);
    try testing.expect(graph_cost > 0.0);
    
    // Test index decision logic
    try testing.expect(cost_model.shouldUseIndex(10000, 0.01) == true); // High selectivity
    // For 1000 items with 0.8 selectivity:
    // Index cost: log(1000) * 50 + 1000 * 0.8 * 100 * 0.1 â‰ˆ 345 + 8000 = 8345
    // Scan cost: 1000 * 100 * 0.8 = 80000
    // Index is actually cheaper even with low selectivity due to the 0.1 factor in result scanning
    try testing.expect(cost_model.shouldUseIndex(1000, 0.8) == true);
}

test "CostModel edge cases" {
    const cost_model = query_optimizer.CostModel{};
    
    // Test with zero items
    const zero_scan = cost_model.estimateLinearScanCost(0, 0.5);
    try testing.expect(zero_scan == 0.0);
    
    // Test with 100% selectivity
    const full_scan = cost_model.estimateLinearScanCost(1000, 1.0);
    const partial_scan = cost_model.estimateLinearScanCost(1000, 0.5);
    try testing.expect(full_scan > partial_scan);
    
    // Test with very low selectivity
    const tiny_selectivity = cost_model.estimateLinearScanCost(10000, 0.001);
    try testing.expect(tiny_selectivity > 0.0);
}

test "QueryOptimizer initialization and cleanup" {
    const allocator = testing.allocator;
    
    var optimizer = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer.deinit();
    
    try testing.expect(optimizer.cache_enabled == true);
    try testing.expect(optimizer.parallel_enabled == false);
    
    const initial_stats = optimizer.getOptimizerStats();
    try testing.expect(initial_stats.total_queries_optimized == 0);
    try testing.expect(initial_stats.total_patterns_learned == 0);
    try testing.expect(initial_stats.cache_hit_ratio == 0.0);
}

test "QueryOptimizer basic optimization" {
    const allocator = testing.allocator;
    
    var optimizer = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer.deinit();
    
    // Test point lookup optimization
    var plan1 = try optimizer.optimizeQuery(.point_lookup, 10000, 0.01);
    defer plan1.deinit();
    try testing.expect(plan1.strategy == .index_lookup); // Should use index for selective query
    try testing.expect(plan1.use_cache == true);
    try testing.expect(plan1.index_hints.items.len > 0);
    
    // Test similarity search optimization
    var plan2 = try optimizer.optimizeQuery(.similarity_search, 5000, 0.1);
    defer plan2.deinit();
    try testing.expect(plan2.strategy == .vector_similarity);
    try testing.expect(plan2.index_hints.items.len > 0);
    
    // Test aggregation with large dataset
    optimizer.parallel_enabled = true;
    var plan3 = try optimizer.optimizeQuery(.aggregation, 15000, 0.5);
    defer plan3.deinit();
    try testing.expect(plan3.strategy == .hybrid);
    try testing.expect(plan3.use_parallel == true);
}

test "QueryOptimizer strategy selection logic" {
    const allocator = testing.allocator;
    
    var optimizer = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer.deinit();
    
    // Test range scan with different selectivities
    var selective_plan = try optimizer.optimizeQuery(.range_scan, 10000, 0.05);
    defer selective_plan.deinit();
    try testing.expect(selective_plan.strategy == .index_lookup);
    
    var broad_plan = try optimizer.optimizeQuery(.range_scan, 10000, 0.3);
    defer broad_plan.deinit();
    try testing.expect(broad_plan.strategy == .linear_scan);
    
    // Test complex filter with different characteristics
    var very_selective = try optimizer.optimizeQuery(.complex_filter, 10000, 0.005);
    defer very_selective.deinit();
    try testing.expect(very_selective.strategy == .index_lookup);
    
    var large_dataset = try optimizer.optimizeQuery(.complex_filter, 8000, 0.1);
    defer large_dataset.deinit();
    try testing.expect(large_dataset.strategy == .hybrid);
    
    var small_dataset = try optimizer.optimizeQuery(.complex_filter, 1000, 0.1);
    defer small_dataset.deinit();
    try testing.expect(small_dataset.strategy == .linear_scan);
}

test "QueryOptimizer cost calculation" {
    const allocator = testing.allocator;
    
    var optimizer = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer.deinit();
    
    // Compare costs of different strategies
    var linear_plan = try optimizer.optimizeQuery(.point_lookup, 1000, 0.5);
    defer linear_plan.deinit();
    
    var index_plan = try optimizer.optimizeQuery(.point_lookup, 10000, 0.01);
    defer index_plan.deinit();
    
    // Index should be cheaper for selective queries on large datasets
    try testing.expect(index_plan.estimated_cost < linear_plan.estimated_cost);
    
    // Test vector similarity cost
    var vector_plan = try optimizer.optimizeQuery(.similarity_search, 5000, 0.1);
    defer vector_plan.deinit();
    try testing.expect(vector_plan.estimated_cost > 0.0);
}

test "QueryOptimizer learning and adaptation" {
    const allocator = testing.allocator;
    
    var optimizer = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer.deinit();
    
    // Record some query executions
    var stats1 = query_optimizer.QueryStats.init();
    stats1.execution_time_ns = 500000;
    stats1.nodes_examined = 100;
    stats1.edges_traversed = 50;
    stats1.cache_hits = 20;
    stats1.cache_misses = 5;
    
    const query_hash = query_optimizer.hashQuery(.point_lookup, 0.1, 1000);
    try optimizer.recordQueryExecution(query_hash, .point_lookup, stats1);
    
    // Check that statistics were recorded
    const optimizer_stats = optimizer.getOptimizerStats();
    try testing.expect(optimizer_stats.total_queries_optimized == 1);
    try testing.expect(optimizer_stats.total_patterns_learned == 1);
    try testing.expect(optimizer_stats.cache_hit_ratio > 0.7);
    
    // Record another execution of the same query
    var stats2 = query_optimizer.QueryStats.init();
    stats2.execution_time_ns = 300000;
    stats2.nodes_examined = 80;
    stats2.cache_hits = 25;
    stats2.cache_misses = 3;
    
    try optimizer.recordQueryExecution(query_hash, .point_lookup, stats2);
    
    const updated_stats = optimizer.getOptimizerStats();
    try testing.expect(updated_stats.total_queries_optimized == 2);
    try testing.expect(updated_stats.total_patterns_learned == 1); // Same pattern
}

test "QueryOptimizer recommendations" {
    const allocator = testing.allocator;
    
    var optimizer = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer.deinit();
    
    // Record slow queries to trigger recommendations
    var slow_stats = query_optimizer.QueryStats.init();
    slow_stats.execution_time_ns = 5_000_000; // 5ms
    slow_stats.cache_hits = 1;
    slow_stats.cache_misses = 10; // Poor cache hit ratio
    slow_stats.memory_allocated = 200_000_000; // 200MB
    
    for (0..10) |i| {
        const hash = query_optimizer.hashQuery(.aggregation, 0.1, @intCast(1000 + i));
        try optimizer.recordQueryExecution(hash, .aggregation, slow_stats);
    }
    
    // Add some recent high-memory queries
    for (0..15) |i| {
        var memory_stats = query_optimizer.QueryStats.init();
        memory_stats.execution_time_ns = 1_000_000;
        memory_stats.memory_allocated = 150_000_000; // 150MB
        memory_stats.cache_hits = 5;
        memory_stats.cache_misses = 5;
        
        const hash = query_optimizer.hashQuery(.join, 0.2, @intCast(2000 + i));
        try optimizer.recordQueryExecution(hash, .join, memory_stats);
    }
    
    const recommendations = try optimizer.getOptimizationRecommendations();
    defer recommendations.deinit();
    
    try testing.expect(recommendations.items.len > 0);
    
    // Should recommend indexes for slow queries
    var has_index_recommendation = false;
    var has_cache_recommendation = false;
    
    for (recommendations.items) |rec| {
        if (std.mem.indexOf(u8, rec, "indexes") != null) {
            has_index_recommendation = true;
        }
        if (std.mem.indexOf(u8, rec, "cache") != null) {
            has_cache_recommendation = true;
        }
    }
    
    try testing.expect(has_index_recommendation);
    try testing.expect(has_cache_recommendation);
    // Memory recommendation might not always trigger depending on the specific data, so we don't test it
}

test "QueryOptimizer deterministic behavior" {
    const allocator = testing.allocator;
    
    // Create two identical optimizers
    var optimizer1 = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer1.deinit();
    
    var optimizer2 = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer2.deinit();
    
    // Same query should produce identical plans
    var plan1 = try optimizer1.optimizeQuery(.point_lookup, 5000, 0.1);
    defer plan1.deinit();
    
    var plan2 = try optimizer2.optimizeQuery(.point_lookup, 5000, 0.1);
    defer plan2.deinit();
    
    try testing.expect(plan1.strategy == plan2.strategy);
    try testing.expect(plan1.estimated_cost == plan2.estimated_cost);
    try testing.expect(plan1.expected_selectivity == plan2.expected_selectivity);
    try testing.expect(plan1.use_cache == plan2.use_cache);
    try testing.expect(plan1.use_parallel == plan2.use_parallel);
}

test "QueryOptimizer reset functionality" {
    const allocator = testing.allocator;
    
    var optimizer = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer.deinit();
    
    // Add some data
    var stats = query_optimizer.QueryStats.init();
    stats.execution_time_ns = 1000;
    const hash = query_optimizer.hashQuery(.point_lookup, 0.1, 1000);
    try optimizer.recordQueryExecution(hash, .point_lookup, stats);
    
    const before_stats = optimizer.getOptimizerStats();
    try testing.expect(before_stats.total_queries_optimized > 0);
    
    // Reset and verify
    optimizer.reset();
    const after_stats = optimizer.getOptimizerStats();
    try testing.expect(after_stats.total_queries_optimized == 0);
    try testing.expect(after_stats.total_patterns_learned == 0);
}

test "QueryOptimizer stress test with many patterns" {
    const allocator = testing.allocator;
    
    var optimizer = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer.deinit();
    
    const pattern_types = [_]query_optimizer.QueryPattern.PatternType{
        .point_lookup, .range_scan, .similarity_search, .graph_traversal,
        .aggregation, .join, .complex_filter
    };
    
    // Generate many different query patterns
    for (pattern_types) |pattern_type| {
        for (0..20) |i| {
            const dataset_size = @as(u32, @intCast((i + 1) * 1000));
            const selectivity = @as(f32, @floatFromInt(i + 1)) / 100.0;
            
            var plan = try optimizer.optimizeQuery(pattern_type, dataset_size, selectivity);
            defer plan.deinit();
            
            // Verify plan validity
            try testing.expect(plan.estimated_cost > 0.0);
            try testing.expect(plan.expected_selectivity >= 0.0 and plan.expected_selectivity <= 1.0);
            
            // Record execution
            var stats = query_optimizer.QueryStats.init();
            // Cap the cost to prevent overflow
            const capped_cost = @min(plan.estimated_cost * 1000.0, @as(f32, @floatFromInt(std.math.maxInt(u32))));
            stats.execution_time_ns = @as(u64, @intFromFloat(capped_cost));
            stats.nodes_examined = @as(u32, @intFromFloat(@as(f32, @floatFromInt(dataset_size)) * selectivity));
            
            const hash = query_optimizer.hashQuery(pattern_type, selectivity, dataset_size);
            try optimizer.recordQueryExecution(hash, pattern_type, stats);
        }
    }
    
    const final_stats = optimizer.getOptimizerStats();
    try testing.expect(final_stats.total_queries_optimized == pattern_types.len * 20);
    try testing.expect(final_stats.total_patterns_learned > 0);
}

test "QueryOptimizer parallel processing decisions" {
    const allocator = testing.allocator;
    
    var optimizer = query_optimizer.QueryOptimizer.init(allocator);
    defer optimizer.deinit();
    
    // Test with parallel disabled
    optimizer.parallel_enabled = false;
    var plan1 = try optimizer.optimizeQuery(.aggregation, 15000, 0.5);
    defer plan1.deinit();
    try testing.expect(plan1.use_parallel == false);
    
    // Test with parallel enabled and large dataset
    optimizer.parallel_enabled = true;
    var plan2 = try optimizer.optimizeQuery(.aggregation, 15000, 0.5);
    defer plan2.deinit();
    try testing.expect(plan2.use_parallel == true);
    
    // Test with parallel enabled but small dataset
    var plan3 = try optimizer.optimizeQuery(.aggregation, 500, 0.5);
    defer plan3.deinit();
    try testing.expect(plan3.use_parallel == false); // Too small for parallel
}

test "hash function deterministic behavior" {
    // Test that the hash function is deterministic
    const hash1 = query_optimizer.hashQuery(.point_lookup, 0.1, 1000);
    const hash2 = query_optimizer.hashQuery(.point_lookup, 0.1, 1000);
    try testing.expect(hash1 == hash2);
    
    // Test that different inputs produce different hashes
    const hash3 = query_optimizer.hashQuery(.range_scan, 0.1, 1000);
    const hash4 = query_optimizer.hashQuery(.point_lookup, 0.2, 1000);
    const hash5 = query_optimizer.hashQuery(.point_lookup, 0.1, 2000);
    
    try testing.expect(hash1 != hash3);
    try testing.expect(hash1 != hash4);
    try testing.expect(hash1 != hash5);
    
    // Test edge cases
    const zero_hash = query_optimizer.hashQuery(.point_lookup, 0.0, 0);
    const max_hash = query_optimizer.hashQuery(.complex_filter, 1.0, std.math.maxInt(u32));
    try testing.expect(zero_hash != max_hash);
} 