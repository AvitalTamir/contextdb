# Memora ğŸ§ 

A **distributed hybrid vector and graph database** designed as an **LLM long-term memory backend** with **human visibility layers**. Built in Zig with **Raft consensus** for reliability, **MCP integration** for LLM access, and **Cypher-like queries** for human exploration.

## ğŸ¯ Bifocal Memory System

Memora serves as a **dual-purpose memory architecture**:

**ğŸ¤– For LLMs**: High-performance semantic memory store via **Model Context Protocol (MCP)**<br />
**ğŸ‘¨â€ğŸ’» For Humans**: Transparent, queryable knowledge graph with **web UI** and **audit capabilities**

### ğŸ’¡ Why This Is Powerful

| Feature | Description |
|---------|-------------|
| ğŸ” **Feedback Loop** | LLMs read/write memories with purpose; humans inspect, audit, and correct |
| ğŸ” **Visibility + Explainability** | Trace answers back to source paragraphs, events, relationships |
| ğŸ”— **Shared World Model** | Graph shows how concepts connect (not just stored) |
| ğŸ§  **Long-Term Memory API** | LLM stores observations, experiences, decisions |
| ğŸ” **Memory Audit** | Devs and users can query what the LLM "knows" |
| ğŸ§© **Cross-Session Coherence** | Persistent memory survives across prompts/sessions |
| ğŸ”— **Traceable Retrieval** | Responses tied to graph+vector provenance |
| ğŸ§‘â€ğŸ’» **Human/LLM Co-curation** | Humans can shape or clean memory alongside the model |

## ğŸ—ï¸ Architecture: Observability Dashboard for Machine Cognition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Memora System                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Access Layer                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   MCP Server    â”‚  â”‚   Web UI         â”‚ â”‚ Cypher-like QL  â”‚ â”‚
â”‚  â”‚ (LLM Interface) â”‚  â”‚ (Human Insight)  â”‚ â”‚ (Dev Queries)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Consensus Layer (Raft Protocol)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Leader Election â”‚  â”‚ Log Replication  â”‚ â”‚ Fault Tolerance â”‚ â”‚
â”‚  â”‚ (150-300ms)     â”‚  â”‚ (TCP + CRC32)    â”‚ â”‚ (Majority)      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Memory Layer                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Concept Graph   â”‚  â”‚ Semantic Vectors â”‚ â”‚ Memory Cache    â”‚ â”‚
â”‚  â”‚ (Knowledge Web) â”‚  â”‚ (Similarity)     â”‚ â”‚ (LRU + LFU)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Storage Layer                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Graph Index    â”‚  â”‚  Vector Index    â”‚ â”‚ Experience Log  â”‚ â”‚
â”‚  â”‚ (Memory-Mapped) â”‚  â”‚ (HNSW Structure) â”‚ â”‚ (Replicated)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Persistence Layer                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Memory Snapshotsâ”‚  â”‚ Network Protocol â”‚ â”‚ S3 Sync         â”‚ â”‚
â”‚  â”‚ (Event Sourcing)â”‚  â”‚ (Binary + CRC32) â”‚ â”‚ (Snapshots)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸŒ API Access

### HTTP REST API

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/v1/health` | Health check and cluster status |
| `GET` | `/api/v1/metrics` | Database metrics and statistics |
| `POST` | `/api/v1/nodes` | Insert a new node |
| `GET` | `/api/v1/nodes/:id` | Get node information |
| `GET` | `/api/v1/nodes/:id/related` | Get related nodes (graph traversal) |
| `POST` | `/api/v1/edges` | Insert a new edge |
| `POST` | `/api/v1/vectors` | Insert a new vector |
| `GET` | `/api/v1/vectors/:id/similar` | Get similar vectors |
| `POST` | `/api/v1/batch` | Batch insert nodes, edges, and vectors |
| `POST` | `/api/v1/query/hybrid` | Execute hybrid graph+vector queries |
| `POST` | `/api/v1/snapshot` | Create a database snapshot |


```bash
# Health check and memory stats
curl http://localhost:8080/api/v1/health

# Store data
curl -X POST http://localhost:8080/api/v1/nodes \
  -H "Content-Type: application/json" \
  -d '{"id": 100, "label": "UserPreference"}'

# Query relationships
curl http://localhost:8080/api/v1/nodes/1/related

# Vector similarity
curl http://localhost:8080/api/v1/vectors/1/similar

# Hybrid queries
curl -X POST http://localhost:8080/api/v1/query/hybrid \
  -H "Content-Type: application/json" \
  -d '{"node_id": 1, "depth": 2, "top_k": 5}'
```

### MCP Server Endpoints

```bash
# Start MCP server
zig build mcp-server --port 9090

# LLMs connect via MCP protocol
# Supports all MCP v1.0 capabilities:
# - Resource discovery
# - Tool invocation  
# - Streaming responses
# - Bidirectional communication
```

## ğŸš€ Quick Start

### Prerequisites

- **Zig 0.14+** - [Install Zig](https://ziglang.org/download/)
- **MCP-compatible LLM** - Claude, GPT-4, or custom implementation

### Setup

```bash
# Clone Memora
git clone <repo-url> memora
cd memora

# Build and start HTTP server
zig build http-server

# Or start MCP server for LLM integration
zig build mcp-server

# Servers run on localhost:8080 (HTTP) and localhost:9090 (MCP)
```

### Basic Usage

```zig
const std = @import("std");
const ContextDB = @import("src/main.zig").ContextDB;
const types = @import("src/types.zig");

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    const config = ContextDB.ContextDBConfig{
        .data_path = "memora_data",
        .enable_persistent_indexes = true,
    };

    var db = try ContextDB.init(allocator, config);
    defer db.deinit();

    // Store knowledge as nodes, edges, vectors
    try db.insertNode(types.Node.init(1, "UserPreference"));
    try db.insertEdge(types.Edge.init(1, 2, types.EdgeKind.related));
    
    const related = try db.queryRelated(1, 2);
    defer related.deinit();
}
```

## ğŸ“Š Data Types

### Core Types

```zig
// Node: Graph vertex with ID and label
const Node = packed struct {
    id: u64,
    label: [32]u8,
};

// Edge: Graph connection with relationship type
const Edge = packed struct {
    from: u64,
    to: u64,
    kind: u8, // EdgeKind enum value
};

// Vector: 128-dimensional embedding
const Vector = packed struct {
    id: u64,
    dims: [128]f32,
};
```

### Edge Types

```zig
const EdgeKind = enum(u8) {
    owns = 0,
    links = 1,
    related = 2,
    child_of = 3,
    similar_to = 4,
};
```

## ğŸ” Query Capabilities

### Graph Queries

```zig
// Find nodes within N hops
const related = try db.queryRelated(start_node_id, depth);

// Hybrid graph+vector queries
const hybrid_result = try db.queryHybrid(start_node_id, depth, top_k);
defer hybrid_result.deinit();
```

### Vector Queries

```zig
// Find K most similar vectors
const similar = try db.querySimilar(vector_id, top_k);
```

## ğŸ’¾ Storage System

### Iceberg-Style File Layout

```
memora/
â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ snapshot-000001.json
â”‚   â”œâ”€â”€ snapshot-000002.json
â”‚   â””â”€â”€ snapshot-000003.json
â”œâ”€â”€ vectors/
â”‚   â”œâ”€â”€ vec-000001.blob       # Binary vector data
â”‚   â”œâ”€â”€ vec-000002.blob
â”‚   â””â”€â”€ vec-000003.blob
â”œâ”€â”€ nodes/
â”‚   â”œâ”€â”€ node-000001.json      # JSON node data
â”‚   â”œâ”€â”€ node-000002.json
â”‚   â””â”€â”€ node-000003.json
â”œâ”€â”€ edges/
â”‚   â”œâ”€â”€ edge-000001.json      # JSON edge data
â”‚   â”œâ”€â”€ edge-000002.json
â”‚   â””â”€â”€ edge-000003.json
â””â”€â”€ memora.log               # Append-only binary log
```

## â˜ï¸ Distributed Memory Architecture

### Multi-Node Memory Clusters

```bash
# Start 3-node cluster
# Node 1 (Leader)
zig build run-distributed -- --node-id=1 --port=8001

# Node 2 (Follower)  
zig build run-distributed -- --node-id=2 --port=8001

# Node 3 (Follower)
zig build run-distributed -- --node-id=3 --port=8001
```

### Memory Replication & Consistency

- **Strong Consistency**: All writes replicated via Raft consensus
- **Read Scaling**: Can read from any node for performance
- **Partition Tolerance**: Continues operating with majority of nodes
- **Automatic Recovery**: Failed nodes catch up automatically when rejoining

## ğŸ§ª Testing

### Test Commands
```bash
# Run all tests
zig build test-all

# Test specific components
zig build test-raft          # Distributed consensus tests
zig build test               # Core database tests
zig build test-http-api      # HTTP REST API tests

# Fuzzing campaigns
zig build fuzz-quick         # Quick fuzzing (50 iterations)
zig build fuzz-stress        # Stress testing with large datasets

# Run distributed demo
zig build demo-distributed   # Interactive cluster demonstration
```

## ğŸ¯ Performance Benchmarks

### Operation Latency

| Operation | Single Node | 3-Node Cluster |
|-----------|-------------|----------------|
| Node Insert | ~200Î¼s | ~2ms |
| Vector Query | ~500Î¼s | ~500Î¼s |
| Graph Traversal | ~1ms | ~1ms |
| Hybrid Query | ~2ms | ~2ms |

### Capacity

- **Nodes/Vectors**: Tested with 100K+ items
- **Concurrent Connections**: HTTP server handles 1000+ connections
- **Memory Usage**: Efficient memory-mapped indexes
- **Storage**: Compressed snapshots with S3 sync

## ğŸš€ Development Roadmap

### Completed Systems âœ…

- **âœ… HNSW Vector Indexing** - O(log n) semantic search capability
- **âœ… Query Optimization Engine** - Intelligent query planning and caching
- **âœ… Caching System** - High-performance memory access with LRU/LFU policies
- **âœ… Parallel Processing System** - Multi-threaded operations with load balancing
- **âœ… Memory-Mapped Persistent Indexes** - Instant startup via disk-backed indexes
- **âœ… Distributed Consensus (Raft)** - Multi-node replication with leader election
- **âœ… HTTP REST API** - Production-ready web API for programmatic access
- **âœ… Monitoring & Metrics** - Comprehensive operation observability
- **âœ… Advanced Configuration System** - Production-ready configuration management

### Strategic Priority Systems ğŸ¯

#### **Priority 1: LLM Integration (Q1 2025)**
- **ğŸ”„ Model Context Protocol (MCP) Server** - Native MCP v1.0 implementation for LLM memory access
- **ğŸ”„ LLM Memory Data Models** - Experiences, concepts, relationships optimized for LLM workflows
- **ğŸ”„ LLM Session Management** - Track memory across conversations and context switches
- **ğŸ”„ Memory Confidence & Provenance** - Help LLMs understand memory reliability and source tracking

#### **Priority 2: Human Visibility (Q1 2025)**
- **ğŸ”„ MemQL Query Language** - Cypher-like syntax for memory exploration and debugging
- **ğŸ”„ Web UI Memory Dashboard** - Visual memory timeline, concept graphs, decision audit trails
- **ğŸ”„ Memory Audit & Curation Tools** - Human interfaces for inspecting and correcting LLM memories
- **ğŸ”„ LLM Decision Provenance Tracking** - Trace responses back to specific memory evidence

#### **Priority 3: Production Operations (Q2 2025)**
- **ğŸ”„ Structured Memory Logging** - Professional debugging and audit trails for memory operations
- **ğŸ”„ Memory Lifecycle Management** - Automatic cleanup, archival, and importance-based retention
- **ğŸ”„ Multi-Tenant Memory** - Isolated memory spaces for different LLMs/users/projects
- **ğŸ”„ Memory Analytics & Insights** - Understanding LLM learning patterns and memory utilization

#### **Priority 4: Advanced Memory Features (Q2-Q3 2025)**
- **ğŸ”„ Memory Compression & Summarization** - Intelligent memory consolidation for long-term storage
- **ğŸ”„ Cross-Model Memory Sharing** - Secure memory exchange between different LLM instances
- **ğŸ”„ Temporal Memory Reasoning** - Time-aware memory retrieval and concept evolution tracking
- **ğŸ”„ Memory Contradiction Detection** - Identify and resolve conflicting memories automatically

#### **Priority 5: Scale & Reliability (Q3-Q4 2025)**
- **ğŸ”„ Horizontal Memory Sharding** - Distribute massive memory datasets across nodes
- **ğŸ”„ Real-time Memory Replication** - Writer-reader replication with memory consistency guarantees
- **ğŸ”„ Memory Backup & Recovery** - Point-in-time memory restoration and disaster recovery
- **ğŸ”„ Advanced Memory Security** - Encryption, access control, and memory privacy protection

### LLM Memory Use Cases ğŸ¤–

- **ğŸ“š Long-term Conversational Memory** - Remember user preferences, context, and history across sessions
- **ğŸ§  Knowledge Accumulation** - Build persistent knowledge from multiple interactions and sources
- **ğŸ” Contextual Decision Making** - Access relevant past experiences for better current responses
- **ğŸ“ˆ Learning & Adaptation** - Track what works, what doesn't, and evolve interaction patterns
- **ğŸ”— Cross-Domain Knowledge Transfer** - Apply insights from one domain to related problems
- **ğŸ¯ Personalization** - Adapt communication style and content based on stored user models

## ğŸ¤ Contributing to LLM Memory Infrastructure

1. Fork the Memora repository
2. Create a feature branch focused on LLM memory capabilities
3. Add comprehensive tests including integration scenarios
4. Run `zig build test-all`
5. Submit a pull request with performance benchmarks

### Development Guidelines

- **Memory First**: All features should enhance LLM memory capabilities
- **Human Debuggable**: Ensure human developers can inspect and understand stored data
- **Deterministic**: Memory operations must be reproducible for testing
- **Performance Critical**: Memory retrieval should be sub-millisecond
- **Privacy Aware**: Design with multi-tenant memory isolation in mind

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **TigerBeetle**: Inspiration for deterministic, high-performance memory backend design
- **Model Context Protocol (MCP)**: Standard for LLM tool integration and memory access
- **Apache Iceberg**: Inspiration for immutable, time-travel capable memory snapshots
- **Zig Community**: For the amazing language perfect for system-level LLM infrastructure

---

**Memora**: *Building the memory layer for the age of AI* ğŸ§ âœ¨

Built with â¤ï¸ and **Zig** for high-performance LLM memory infrastructure.
